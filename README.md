
# YOLOv8n Object Detection Model for the Visually Impaired ğŸš¶â€â™€ï¸ğŸ‘ï¸

Achieved high detection accuracy â€” correctly identifying most obstacles in real-time with an average precision (**mAP**) of **66%** and smooth guidance at approximately **77 FPS (â‰ˆ6 ms/frame)**.

---

## ğŸš€ Overview

This project implements and fine-tunes the **Ultralytics YOLOv8n (Nano)** model for efficient, real-time obstacle detection to assist visually impaired navigation.
It delivers an excellent balance between **speed and accuracy**, optimized for deployment on edge devices.

---

## ğŸ§  Model Details

* **Base Model:** `YOLOv8n`
* **Framework:** `Ultralytics`
* **Training Type:** Transfer learning on a custom obstacle dataset
* **Output:** Bounding boxes, class labels, and confidence scores

---

## ğŸ“ Repository Contents

| File / Folder          | Description                         |
| ---------------------- | ----------------------------------- |
| `robust_final_last.pt` | Final trained YOLOv8n model weights |
| `train_yolov8n.py`     | Training code used for fine-tuning  |
| `README.md`            | Documentation and usage guide       |

---

## â˜ï¸ Cloud Training Advantage

This training pipeline is fully **Google Colabâ€“compatible**, enabling seamless execution across different Google accounts.
By leveraging **Google Driveâ€“based checkpoints**, training sessions can be **paused, resumed, or transferred** effortlessly â€” ensuring:

* ğŸ” Continuous training flexibility (even if GPU limits reset)
* â˜ï¸ Persistent data and model storage in the cloud
* ğŸ¤ Easy collaboration and cross-device accessibility

This design makes the workflow **robust, portable, and ideal for research or real-world deployment** scenarios.

---




